{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU5jt12P-MhF"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/drive/MyDrive/003/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxmzAp3IbNtD"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmDhWssy-MhK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import re,os\n",
        "import unicodedata\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn import metrics, feature_selection\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, brier_score_loss,accuracy_score,classification_report,accuracy_score,confusion_matrix,recall_score,precision_score,roc_curve\n",
        "from transformers import Trainer, TrainingArguments, EvalPrediction,DataCollatorWithPadding, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
        "from transformers import BertModel, BertConfig, BertTokenizer, DebertaConfig, DebertaModel, DebertaTokenizer,DebertaV2Model, DebertaV2Config,DebertaV2Tokenizer,AutoTokenizer,AutoModel,AutoConfig\n",
        "import optuna.visualization as optuna_visualization\n",
        "import plotly\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import optuna\n",
        "from optuna.visualization import plot_optimization_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xXE3vLU-MhL"
      },
      "outputs": [],
      "source": [
        "device=torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NgV1kMXeWHM"
      },
      "outputs": [],
      "source": [
        "# CON DEBERTA\n",
        "tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "config = DebertaConfig.from_pretrained(\"microsoft/deberta-base\", output_hidden_states=True, output_attentions=True)\n",
        "MODEL = DebertaModel.from_pretrained(\"microsoft/deberta-base\", config=config)\n",
        "MODEL_TYPE = 'deberta'\n",
        "\n",
        "# CON MDEBERTA\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/mdeberta-v3-base\")\n",
        "# config = AutoConfig.from_pretrained(\"microsoft/mdeberta-v3-base\",output_hidden_states=True, output_attentions=True)\n",
        "# MODEL = AutoModel.from_pretrained(\"microsoft/mdeberta-v3-base\", config=config)\n",
        "# MODEL_TYPE = 'mdeberta'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL73SxzKnf7P"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "date_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY6PEYKn-MhM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"/content/drive/MyDrive/003/dataok.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ0ffaV45Qkc"
      },
      "outputs": [],
      "source": [
        "# df = df.iloc[:200,:]\n",
        "# df = pd.concat([df,df,df,df]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCp0BS03FSA1"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yreECtSMakq3"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egsRwcP4TXDh"
      },
      "outputs": [],
      "source": [
        "rutabase= '/content/drive/MyDrive/003'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBPXLr5tTNs1"
      },
      "outputs": [],
      "source": [
        "def GenerarDirectorio(name):\n",
        "    directorio = os.path.join(rutabase, name)\n",
        "    if not os.path.exists(directorio):\n",
        "        os.makedirs(directorio)\n",
        "    return directorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdENXpv-cqiv"
      },
      "outputs": [],
      "source": [
        "if MODEL_TYPE=='mdeberta':\n",
        "  dataTrainer = pd.read_json(f\"{rutabase}/mdebertaTokenizer.json\")\n",
        "  dataEvaluation = pd.read_json(f\"{rutabase}/mdebertaTokenizereval.json\")\n",
        "  datatest = pd.read_json(f\"{rutabase}/mdebertaTokenizertest.json\")\n",
        "elif MODEL_TYPE=='deberta':\n",
        "  dataTrainer = pd.read_json(f\"{rutabase}/ebertaTokenizer.json\")\n",
        "  dataEvaluation = pd.read_json(f\"{rutabase}/ebertaTokenizereval.json\")\n",
        "  datatest = pd.read_json(f\"{rutabase}/mdebertaTokenizertest.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcI9wnU1ErVt"
      },
      "outputs": [],
      "source": [
        "datatest=datatest.iloc[:50,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnZU1fIdErSH"
      },
      "outputs": [],
      "source": [
        "datatest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62Ntu8JuOeVQ"
      },
      "outputs": [],
      "source": [
        "dataTrainer=dataTrainer.iloc[:250,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ccj6bO4fegKR"
      },
      "outputs": [],
      "source": [
        "dataTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJOf_HfpOX3i"
      },
      "outputs": [],
      "source": [
        "dataEvaluation=dataEvaluation.iloc[:120,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5x-gPu5ejY-"
      },
      "outputs": [],
      "source": [
        "dataEvaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LsqH5NA-MhQ"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):             # define una nueva clase MyDataset que hereda de Dataset\n",
        "    def __init__(self, dataframe):    # define el constructor  \"__init__\"  que toma un solo argumento dataframe\n",
        "        #print(dataframe)\n",
        "        self.len = len(dataframe)   # calcula la longitud de la entrada dataframe usando la funcion \"len\" y la almacena como una variable de instancia \"self.len\"\n",
        "        self.data = dataframe       # se asigna la entrada dataframe a una variable de instancia \"self.data\"\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):   # define el método \"__getitem__\" que toma un solo argumento index\n",
        "        ''' el metodo __getitem__ devuelve un diccionario que contiene cuatro claves: 'input_ids', 'attention_mask', 'labels'y 'added_features' '''\n",
        "\n",
        "        input_ids = torch.tensor(self.data.text_vec.iloc[index]).cpu() # almacena las características de los datos de \"text_vec\" ​​que se han convertido en un vector de longitud fija.\n",
        "        #attention_mask = torch.ones([input_ids.size(0)]).cpu()  # attention_mask almacena los elementos de entrada que se debe prestar atención y cuáles se deben ignorar\n",
        "        #\n",
        "        mask = torch.ones(input_ids.shape,dtype=int)#Crear un tensor con el mismo tamaño que input_ids lleno de unos:\n",
        "        pad_positions = (input_ids == 0)#Identificar las posiciones en input_ids que contienen el token especial [PAD]\n",
        "        mask[pad_positions] = 0 #Actualizar las posiciones correspondientes en mask a cero:\n",
        "        attention_mask = mask #Actualizar las posiciones correspondientes en mask a cero:\n",
        "        #\n",
        "        label = self.data.same.iloc[index] # almacena un valor escalar que representa la etiqueta de salida para la puntuación de complejidad\n",
        "        targets = torch.tensor([1 - label, label])  #ojo probar ESTO ES NUEVO\n",
        "        return {\n",
        "            'input_ids': input_ids,               # devuelve las características de entrada para el punto de datos\n",
        "            'attention_mask': attention_mask,     # devuelve la máscara de atención para el punto de datos\n",
        "            'labels': targets                    # devuelve un valor escalar que representa la puntuación de complejidad\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len   # devuelve la longitud del conjunto de datos personalizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYILtDQCEM5y"
      },
      "outputs": [],
      "source": [
        "train_set, eval_dataset = MyDataset(dataTrainer), MyDataset(dataEvaluation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVnmd-nT5bJK"
      },
      "outputs": [],
      "source": [
        "train_set.len, eval_dataset.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG2qwMKbeZ5I"
      },
      "outputs": [],
      "source": [
        "train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cifhG6tW2t-L"
      },
      "outputs": [],
      "source": [
        "def c_at_1(train_data, test_data, threshold=0.5):\n",
        "      n = float(len(test_data))\n",
        "      nc, nu = 0.0, 0.0\n",
        "\n",
        "      for gt_score, pred_score in zip(train_data, test_data):\n",
        "        if pred_score == 0.5:\n",
        "          nu += 1\n",
        "        elif (pred_score > 0.5) == (gt_score > 0.5):\n",
        "          nc += 1.0\n",
        "\n",
        "      return (1 / n) * (nc + (nu * nc / n))\n",
        "\n",
        "def binarize(y, threshold=0.5, triple_valued=False):\n",
        "    y = np.array(y)\n",
        "    y = np.ma.fix_invalid(y, fill_value=threshold)\n",
        "    if triple_valued:\n",
        "        y[y > threshold] = 1\n",
        "    else:\n",
        "        y[y >= threshold] = 1\n",
        "    y[y < threshold] = 0\n",
        "    return y\n",
        "\n",
        "def f_05_u_score(train_data, test_data, pos_label=1, threshold=0.5):\n",
        "\n",
        "      test_data = binarize(test_data)\n",
        "\n",
        "      n_tp = 0\n",
        "      n_fn = 0\n",
        "      n_fp = 0\n",
        "      n_u = 0\n",
        "\n",
        "      for i, pred in enumerate(test_data):\n",
        "        if pred == threshold:\n",
        "          n_u += 1\n",
        "        elif pred == pos_label and pred == train_data[i]:\n",
        "          n_tp += 1\n",
        "        elif pred == pos_label and pred != train_data[i]:\n",
        "          n_fp += 1\n",
        "        elif train_data[i] == pos_label and pred != train_data[i]:\n",
        "          n_fn += 1\n",
        "\n",
        "      return (1.25 * n_tp) / (1.25 * n_tp + 0.25 * (n_fn + n_u) + n_fp)\n",
        "\n",
        "def brier_score(train_data, test_data):\n",
        "      try:\n",
        "        return 1 - brier_score_loss(train_data, test_data)\n",
        "      except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "def auc_score(train_data, test_data):\n",
        "    try:\n",
        "        return roc_auc_score(train_data, test_data)\n",
        "    except ValueError:\n",
        "        return 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlzkKYSKA5eD"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p: EvalPrediction): # calcula diversas métricas de evaluación\n",
        "  preds = np.argmax(p.predictions,axis=-1)\n",
        "  preds = np.squeeze(preds)\n",
        "  labels = np.argmax(p.label_ids,axis=-1)\n",
        "  labels = np.squeeze(labels)\n",
        "  precision = precision_score(labels, preds, average='micro')\n",
        "  precision_macro = precision_score(labels, preds, average='macro')\n",
        "  auc = auc_score(labels, preds)\n",
        "  #mse = metrics.mean_squared_error(labels, preds)# Se toma el primer indice del label\n",
        "  #print(\"SIZES::::\",labels.shape, preds.shape)\n",
        "\n",
        "\n",
        "  return {\n",
        "      'Accuracy-RC': accuracy_score(labels, preds),\n",
        "          'auc': auc,\n",
        "          'c@1': c_at_1(labels, preds),\n",
        "          'f_05_u': f_05_u_score(labels, preds),\n",
        "          'F1': f1_score(labels, preds, average = 'micro'),\n",
        "          'brier': brier_score(labels, preds),\n",
        "          'precision micro': precision,\n",
        "          'precision macro': precision_macro\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Xi6SQJjEpgX"
      },
      "outputs": [],
      "source": [
        "# Definir bien los argumentos\n",
        "args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/003/output',  # Ruta del directorio de salida donde se guardarán los resultados del entrenamiento\n",
        "    evaluation_strategy='epoch',  # Evaluación del modelo al final de cada época\n",
        "    num_train_epochs=7,  # Número total de épocas de entrenamiento\n",
        "    per_device_train_batch_size=16,  # Tamaño del lote de entrenamiento por dispositivo. Ajustar según la memoria GPU disponible\n",
        "    per_device_eval_batch_size=16,  # Tamaño del lote de evaluación por dispositivo. Ajustar según la memoria GPU disponible\n",
        "    learning_rate=5e-5,  # Tasa de aprendizaje utilizada en el entrenamiento\n",
        "    overwrite_output_dir=True,  # Sobrescribir el directorio de salida si ya existe\n",
        "    remove_unused_columns=False,  # No eliminar columnas no utilizadas del conjunto de datos\n",
        "    logging_dir='/content/drive/MyDrive/003/logs',  # Ruta del directorio donde se guardarán los archivos de registro del entrenamiento\n",
        "    logging_steps=10,  # Número de pasos después de los cuales se realizará el registro\n",
        "    save_strategy='epoch',  # Estrategia de guardado del modelo: al final de cada época\n",
        "    save_total_limit=10,  # Límite total de modelos guardados\n",
        "    load_best_model_at_end=True,  # Cargar el mejor modelo al final del entrenamiento\n",
        "    warmup_steps=10,  # Número de pasos de calentamiento antes de ajustar la tasa de aprendizaje\n",
        "    weight_decay=0.03,  # Factor de decaimiento de peso para la regularización L2\n",
        "    adam_epsilon=1e-8,  # Epsilon para el optimizador Adam, utilizado para la estabilidad numérica\n",
        "    adam_beta1=0.5,  # Coeficiente beta1 para el optimizador Adam\n",
        "    adam_beta2=0.5,  # Coeficiente beta2 para el optimizador Adam\n",
        "    lr_scheduler_type='cosine',  # Tipo de programador de tasa de aprendizaje: programador coseno curva de aprendizaje  entre el eje x\n",
        "    gradient_accumulation_steps=1,  # Número de pasos de acumulación de gradiente antes de realizar una actualización de parámetros\n",
        "    max_grad_norm=5.0,  # Valor máximo de la norma del gradiente para evitar explosiones de gradiente\n",
        "    save_steps=10  # Número de pasos después de los cuales se guarda el modelo\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isbFdendEucj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0lUJcyH1_4J"
      },
      "outputs": [],
      "source": [
        "# Metricas realizadas durante la predicción\n",
        "def metricas_preds(preds, label):\n",
        "  return {\n",
        "          'F1-macro-RC': f1_score(label, preds, average='macro'),\n",
        "          'F1-bynary-RC': f1_score(label, preds, average='binary'),\n",
        "          'Accuracy-RC': accuracy_score(label, preds),\n",
        "          'Precision_Score_Macro_RC': precision_score(label, preds, average='macro'),\n",
        "          'Precision_Score_Micro_RC': precision_score(label, preds, average='micro'),\n",
        "          'Precision_Score_Weighted_RC': precision_score(label, preds, average='weighted')\n",
        "\n",
        "          }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jLmJSCJ9Jta"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MyTrainer(Trainer):\n",
        "      def _init_(self, **kwargs):\n",
        "            super()._init_(**kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19OtB5_W-M3h"
      },
      "outputs": [],
      "source": [
        "PATH_historial_optuna = rutabase +\"EN-historial_optuna-rango.csv\"\n",
        "PATH_modelo = rutabase + 'EN-ModeloEntrenadoOptuna-rango.pt'\n",
        "# Guardar los mejores parametros en un archivo\n",
        "PATH_parametros = rutabase + \"EN-mejores_hiperparametros-rango.json\"\n",
        "# Guardar graficas y resultados\n",
        "PATH_resultados_preds = rutabase +\"EN-resultado_metricas_preds-rango.json\"\n",
        "PATH_predicciones = rutabase +\"EN-dataPreds_predicciones-rango.json\"\n",
        "PATH_imagen_matriz = rutabase +\"EN-matriz_confusion_preds-rango.png\"\n",
        "PATH_grafico_optuna = rutabase +\"EN-grafico_optuna-rango.png\"\n",
        "PATH_grafico_optuna_param = rutabase +\"EN-grafico_optuna_trials-rango.png\"\n",
        "PATH_historial_optuna = rutabase +\"EN-historial_optuna-rango.csv\"\n",
        "PATH_result_train = rutabase +\"EN-resultados-train-metricas.json\"\n",
        "PATH_result_eval = rutabase +\"EN-resultados-eval-metricas.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8YHC_iv-MhR"
      },
      "outputs": [],
      "source": [
        "class StackedCLSModel(nn.Module):\n",
        "      def __init__(self,lstm_dict, model=MODEL, model_type=MODEL_TYPE):\n",
        "        super(StackedCLSModel, self).__init__()\n",
        "                            # método __init__ nos aseguramos de que el módulo de red neuronal herede las propiedades y métodos de la clase nn.Module\n",
        "        self.model = MODEL # almacene la ruta al modelo pre-entrenado el tipo de modelo\n",
        "        self.model_type = MODEL_TYPE # almacene la ruta al tipo de modelo\n",
        "        self.Fusion = nn.Parameter(torch.zeros(12,1)) # se utiliza para crear un tensor de tamaño (12, 1) lleno de ceros y convertirlo en un parámetro de la red neuronal para que pueda ser optimizado durante el entrenamiento.\n",
        "        self.dropout =  nn.Dropout(lstm_dict['dropout_rate']) # crea una capa de abandono con una probabilidad de abandono de 0,3\n",
        "\n",
        "        #escoger la función de activación mas apropiada.\n",
        "        if lstm_dict['func_activation'] == \"tanh\":\n",
        "          self.funActivacion = nn.Tanh()\n",
        "        elif lstm_dict['func_activation'] == \"relu\":\n",
        "          self.funActivacion = nn.ReLU()\n",
        "        elif lstm_dict['func_activation'] == \"gelu\":\n",
        "          self.funActivacion = nn.GELU()\n",
        "\n",
        "        self.lin1 = nn.Linear(768, 384)#crea una capa lineal en PyTorch que se utiliza en una red neuronal\n",
        "                                       #para realizar una transformación lineal de las características de entrada de tamaño 768 a características de salida de tamaño 128\n",
        "                                       #que se utiliza en un modelo BERT para procesar la entrada de texto.\n",
        "        self.lin2 = nn.Linear(384, 2)\n",
        "        self.loss_func = nn.CrossEntropyLoss() # establece la función de pérdida que se utilizará durante el entrenamiento\n",
        "      def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "        if self.model_type == \"bert\":\n",
        "          cls_tensors = torch.stack([outputs[2][n][:, 0, :] for n in range(1, 13)])\n",
        "        elif self.model_type == \"deberta\":\n",
        "          cls_tensors = torch.stack([outputs[1][n][:, 0, :] for n in range(1, 13)])\n",
        "        t_cls_tensors = cls_tensors.transpose(1, 0)\n",
        "        t_cls_tensors_mean = torch.mean(t_cls_tensors, dim=1)  # Reducción de la dimensión 12 a 2\n",
        "        x = self.lin1(t_cls_tensors_mean)\n",
        "        x = self.dropout(x)\n",
        "        x = self.funActivacion(x)\n",
        "        logit = self.lin2(x)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "          loss = self.loss_func(logit, labels.float())\n",
        "\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logit)\n",
        "      def predict(self, input_ids, attention_mask,labels):\n",
        "          logits = self.forward(input_ids, attention_mask, labels=None)\n",
        "          # predicciones = logits.logits.argmax(dim=1)\n",
        "          # predicciones =np.argmax(predicciones.tolist(),axis=-1)\n",
        "          # return predicciones.tolist()\n",
        "          logits = self.forward(input_ids, attention_mask, labels=None)\n",
        "          logits = logits.logits\n",
        "          logits = logits.detach().numpy() #lo convertimos en un tipo de dato numpy para poder manipularlo\n",
        "          logits = np.argmax(logits,axis=-1) #aplicamos la función argmax para obtener el indice con mayor valor\n",
        "          logits = logits[0]\n",
        "          return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfHP1aXr2ZBx"
      },
      "outputs": [],
      "source": [
        "\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "#                    Entrenamiento Optuna y objetivo\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "###### Definición de Hiperparámetros ######\n",
        "#funcion de activación\n",
        "activation_options = [\"tanh\",\"relu\", \"gelu\"]\n",
        "\n",
        "#Dropout\n",
        "dropout_min = 0.2\n",
        "dropout_max = 0.5\n",
        "\n",
        "#Learning rate\n",
        "lr_rate_min = 3e-5\n",
        "lr_rate_max = 5e-5\n",
        "\n",
        "#epochs\n",
        "MIN_EPOCHS = 1\n",
        "MAX_EPOCHS = 5\n",
        "\n",
        "#Batchs\n",
        "BATCHS_options = [8,16,32]\n",
        "\n",
        "\n",
        "def objective(trial: optuna.Trial):\n",
        "\n",
        "    lstm_dict = {'dropout_rate': trial.suggest_loguniform(\"dropout\", low= dropout_min, high= dropout_max),\n",
        "                 'func_activation': trial.suggest_categorical(\"func_activ\", activation_options)}\n",
        "\n",
        "    model = StackedCLSModel(lstm_dict,MODEL,MODEL_TYPE) #inicialización del modelo\n",
        "    model.to(device)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='output', #Directorio de salida donde se guardarán los archivos generados durante el entrenamiento\n",
        "        #evaluation_strategy='epoch', #la evaluación se realiza después de cada época\n",
        "        learning_rate=trial.suggest_loguniform('learning_rate', low=lr_rate_min, high=lr_rate_max),\n",
        "        #num_train_epochs=3,\n",
        "        num_train_epochs=trial.suggest_int('num_epochs', low = MIN_EPOCHS,high = MAX_EPOCHS),\n",
        "        remove_unused_columns=False, #se eliminarán las columnas no utilizadas en los datos de entrenamiento y evaluación\n",
        "        per_device_train_batch_size=trial.suggest_categorical(\"batch_opt\", BATCHS_options),\n",
        "        per_device_eval_batch_size=trial.suggest_categorical(\"batch_opt\", BATCHS_options))\n",
        "\n",
        "    trainer = MyTrainer(\n",
        "        model=model,\n",
        "        compute_metrics=compute_metrics,\n",
        "        args=training_args,\n",
        "        train_dataset=train_set,\n",
        "        eval_dataset=eval_dataset)\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "\n",
        "    #Se define cual sera el objetivo a minimizar o maximizar\n",
        "    evaluation_result = trainer.evaluate()\n",
        "    #validation_loss = evaluation_result['eval_loss']\n",
        "    #train_loss = result.training_loss\n",
        "    accuracy = evaluation_result['eval_Accuracy-RC']\n",
        "    f1_macro = evaluation_result['eval_F1']\n",
        "\n",
        "    #return validation_loss, train_loss , accuracy\n",
        "    return f1_macro , accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u6imHom2gms"
      },
      "outputs": [],
      "source": [
        "\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "#                    Definición de early stop - Optuna\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "OPTUNA_EARLY_STOPING = 4 # Aqui se define el stop, si los resultados de optuna siguen siendo iguales luego de 10 trials seguidos, entonces detener la optimización\n",
        "\n",
        "class EarlyStoppingExceeded(optuna.exceptions.OptunaError):\n",
        "    early_stop = OPTUNA_EARLY_STOPING\n",
        "    early_stop_count = 0\n",
        "    best_score = None\n",
        "\n",
        "def early_stopping_opt(study, trial):\n",
        "    resultados_optuna = max(study.best_trials, key=lambda t: t.values[1])\n",
        "    best_f1 = resultados_optuna.values[0]\n",
        "\n",
        "    if EarlyStoppingExceeded.best_score == None:\n",
        "      EarlyStoppingExceeded.best_score = best_f1\n",
        "\n",
        "    if best_f1 < EarlyStoppingExceeded.best_score:\n",
        "        EarlyStoppingExceeded.best_score = best_f1\n",
        "        EarlyStoppingExceeded.early_stop_count = 0\n",
        "    else:\n",
        "      if EarlyStoppingExceeded.early_stop_count > EarlyStoppingExceeded.early_stop:\n",
        "            EarlyStoppingExceeded.early_stop_count = 0\n",
        "            best_score = None\n",
        "            raise EarlyStoppingExceeded()\n",
        "      else:\n",
        "            EarlyStoppingExceeded.early_stop_count=EarlyStoppingExceeded.early_stop_count+1\n",
        "    #print(f'EarlyStop counter: {EarlyStoppingExceeded.early_stop_count}, Best score: {study.best_value} and {EarlyStoppingExceeded.best_score}')\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNja94MN2ucQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "#                    Creación del estudio Optuna\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "print('Activación del estudio de Optuna')\n",
        "study = optuna.create_study(directions=[\"maximize\", \"maximize\"]) # multiples objetivos\n",
        "\n",
        "#para ejecución sin early stop\n",
        "#study.optimize(func=objective, n_trials=NUM_TRIALS)\n",
        "\n",
        "# ejecucion con early stop\n",
        "try:\n",
        "    study.optimize(objective, timeout=60, callbacks=[early_stopping_opt])\n",
        "except EarlyStoppingExceeded:\n",
        "    print(f'EarlyStopping Exceeded: No hay nuevos mejores puntajes en iteraciones {OPTUNA_EARLY_STOPING}')\n",
        "\n",
        "#### Guardar historial ###\n",
        "trials_df = study.trials_dataframe()\n",
        "trials_df.to_csv(PATH_historial_optuna, index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUoUSS8kA42E"
      },
      "outputs": [],
      "source": [
        "\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "#                    Gráficas\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "### Grafico 1 ###\n",
        "grafico_optuna1 = optuna.visualization.matplotlib.plot_pareto_front(study, target_names=[\"f1\", \"accuracy\"])\n",
        "# Ajustar el tamaño de la figura\n",
        "fig1 = grafico_optuna1.figure\n",
        "fig1.set_size_inches(20, 10)  # Ajusta el tamaño según tus necesidades\n",
        "fig1.savefig(PATH_grafico_optuna, dpi=400)  # Guardado de imagen\n",
        "\n",
        "\n",
        "### Grafico 2 ###\n",
        "grafico_optuna2 = optuna.visualization.matplotlib.plot_optimization_history(study, target=lambda t: t.values[0])\n",
        "# Ajustar el tamaño de la figura\n",
        "fig2 = grafico_optuna2.figure\n",
        "fig2.set_size_inches(20, 10)  # Ajusta el tamaño según tus necesidades\n",
        "fig2.savefig(PATH_grafico_optuna_param, dpi=400)  # Guardado de imagen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLpbdJYOBRnX"
      },
      "outputs": [],
      "source": [
        "\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "#                    Parametros encontrados con Optuna\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "print(study.best_trials)\n",
        "resultados_optuna = max(study.best_trials, key=lambda t: t.values[1])\n",
        "print(resultados_optuna.values)\n",
        "\n",
        "print('Encontrar los mejores parámetros del estudio')\n",
        "\n",
        "best_dropout = float(resultados_optuna.params['dropout'])\n",
        "best_func_act = resultados_optuna.params['func_activ']\n",
        "best_lr = float(resultados_optuna.params['learning_rate'])\n",
        "best_epochs = float(resultados_optuna.params['num_epochs'])\n",
        "best_batch = resultados_optuna.params['batch_opt']\n",
        "\n",
        "print('Extraer los mejores parámetros de estudio')\n",
        "\n",
        "print(f'El mejor dropout es: {best_dropout}')\n",
        "print(f'La mejor funcion de activación es: {best_func_act}')\n",
        "print(f'El mejor learning rate is: {best_lr}')\n",
        "print(f'El mejor epochs is: {best_epochs}')\n",
        "print(f'El mejor batch is: {best_batch}')\n",
        "\n",
        "\n",
        "print('Crear diccionario de los mejores hiperparámetros')\n",
        "best_hp_dict = {\n",
        "    'best_dropout' : best_dropout,\n",
        "    'best_func_act' : best_func_act,\n",
        "    'best_learning_rate' : best_lr,\n",
        "    'best_epochs': best_epochs,\n",
        "    'best_batch' : best_batch\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mkp-Ceb2Bj9h"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Abrir el archivo en modo escritura\n",
        "with open(PATH_parametros, \"w\") as archivo:\n",
        "    # Guardar el diccionario como JSON en el archivo\n",
        "    json.dump(best_hp_dict, archivo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKfTeSu8B7Iu"
      },
      "outputs": [],
      "source": [
        "\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "#                    Entrenamiento con los mejores parametros\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "lstm_dict = None\n",
        "lstm_dict = {'dropout_rate': best_dropout,\n",
        "              'func_activation': best_func_act}\n",
        "\n",
        "#model = None\n",
        "model = StackedCLSModel(lstm_dict,MODEL, MODEL_TYPE) #inicialización del modelo\n",
        "\n",
        "# definir bien los arg\n",
        "training_args = TrainingArguments(  # configuracion o argumentos de la forma en que se realizará el entrenamiento y evaluacion del modelo\n",
        "    output_dir='output', #Directorio de salida donde se guardarán los archivos generados durante el entrenamiento\n",
        "    #evaluation_strategy='epoch', #la evaluación se realiza después de cada época\n",
        "    learning_rate=best_lr,\n",
        "    #eval_steps=1000, Número de pasos de actualización entre dos evaluaciones si\n",
        "    #num_train_epochs=3, #número de épocas de entrenamiento que se realizarán\n",
        "    num_train_epochs = best_epochs,\n",
        "    remove_unused_columns=False, #se eliminarán las columnas no utilizadas en los datos de entrenamiento y evaluación\n",
        "    per_device_train_batch_size=best_batch, #Tamaño del lote de entrenamiento por dispositivo\n",
        "    per_device_eval_batch_size=best_batch, #Tamaño del lote de evaluación por dispositivo\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3cH1ByDB-Vn"
      },
      "outputs": [],
      "source": [
        "trainer = MyTrainer(\n",
        "    model=model,\n",
        "    compute_metrics=compute_metrics,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=eval_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j35DW6YODcUl"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Training\")\n",
        "result = trainer.train()\n",
        "evaluation_result = trainer.evaluate()\n",
        "\n",
        "with open(PATH_result_train, \"w\") as archivo:\n",
        "    # Guardar el diccionario como JSON en el archivo\n",
        "    json.dump(result, archivo)\n",
        "\n",
        "with open(PATH_result_eval, \"w\") as archivo:\n",
        "    # Guardar el diccionario como JSON en el archivo\n",
        "    json.dump(evaluation_result, archivo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2Nbw9bkDjso"
      },
      "outputs": [],
      "source": [
        "\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "#                    Guardado del modelo\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "torch.save(trainer.model.state_dict(), PATH_modelo)\n",
        "print(\"FINALIZADO ---> modelo guardado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj0xCTsgDnnR"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------------------------------------------------------------\n",
        "#                    Carga del modelo\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "#carga del modelo base\n",
        "#modelocarga = StackedCLSModel(lstm_dict,MODEL, MODEL_TYPE)\n",
        "\n",
        "#carga del modelo entrenado al modelo base\n",
        "#modelocarga.load_state_dict(torch.load(PATH_modelo, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
        "#modelocarga.eval()\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGz-Uvm3FAEA"
      },
      "outputs": [],
      "source": [
        "datatest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_uINwxpFyLd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Crear el dataset\n",
        "mydata = MyDataset(datatest)\n",
        "\n",
        "# Ajustar el tamaño del lote según tus necesidades\n",
        "batch_size = 16\n",
        "\n",
        "# Crear un DataLoader para recorrer el dataset en lotes\n",
        "dataloader = DataLoader(mydata, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Recorrer el DataLoader por lotes\n",
        "for batch in dataloader:\n",
        "    # Obtener los datos del lote\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels = batch['labels']\n",
        "\n",
        "    # Mover los tensores al dispositivo adecuado (por ejemplo, GPU si está disponible)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Aquí deberías cargar el modelo previamente entrenado o definir uno nuevo si es necesario\n",
        "\n",
        "    # Llamar al método predict en el modelo\n",
        "    predicciones = model.predict(input_ids, attention_mask)\n",
        "\n",
        "    # Aquí puedes realizar cualquier operación adicional que necesites con las predicciones\n",
        "\n",
        "    # Por ejemplo, puedes crear un DataFrame con las predicciones y guardar los resultados\n",
        "    data = {'changes': predicciones}\n",
        "    texts = pd.DataFrame(data)\n",
        "    texts.to_json(os.path.join(folderComplete, f'solution-problem-{instansc}.json'), orient='records')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0tVi1d0H56R"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf5-wS0oGgJm"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku-Sc5R2Du1B"
      },
      "outputs": [],
      "source": [
        "datatest['same'] = datatest['label'].apply(lambda x: 1 if x == 'human' else 0) #crea en el dataframe una columna con el nombre de \"same\" y compara con la columna \"label\" si es human -> 1 caso contrario ->0\n",
        "#vectorización\n",
        "datatest['text_vec'] = datatest.apply(lambda r: vectorize_text(r['text'], 512), axis=1)\n",
        "#llamado del dataset\n",
        "df_preds_set = MyDataset(df_preds)\n",
        "\n",
        "df_preds[\"predict\"] = \"\"\n",
        "\n",
        "predict_test = []\n",
        "data_test =[]\n",
        "\n",
        "for i in range(len(df_preds)):\n",
        "  predict_test = model.predictOJO(torch.stack([df_preds_set[i]['input_ids']]),torch.stack([df_preds_set[i]['attention_mask']]))\n",
        "\n",
        "  data_test.append(predict_test) #agregamos los datos en un array que continene el orden de las filas que vamos a predecir\n",
        "df_preds['predict'] = data_test # agregamos ese resultado en una columna del dato que hicimos la predicción\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPO3yOdL0Vsj"
      },
      "outputs": [],
      "source": [
        "study.best_trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74BsA_45R0KY"
      },
      "outputs": [],
      "source": [
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AvPHlgoV_WW"
      },
      "outputs": [],
      "source": [
        "study.best_trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rrnnk_14QyT7"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJdUh5D_OQ34"
      },
      "outputs": [],
      "source": [
        "optuna_visualization.plot_slice(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFUEUD3qU0rZ"
      },
      "outputs": [],
      "source": [
        "trial = study.best_trial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7faDSygOU2SP"
      },
      "outputs": [],
      "source": [
        "trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No16drFDQ6Lm"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_contour(study, params=['learning_rate', 'num_layers'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZMtLEkmOErj"
      },
      "outputs": [],
      "source": [
        "trial = study.best_trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htIrE9HXOPt-"
      },
      "outputs": [],
      "source": [
        "trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUbPeyh4K2f8"
      },
      "outputs": [],
      "source": [
        "study.optimize(objective, n_trials=7)  # Ajusta el número de ensayos según tus necesidades\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNbiCdK0gqXz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGrkAco5-MhU"
      },
      "outputs": [],
      "source": [
        "result=None\n",
        "result=trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP4OXiAltPVX"
      },
      "outputs": [],
      "source": [
        "result.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c6qUdNrT92q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7tUt1cQUEga"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlmDmlFVspAV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def group_by_property(metrics):\n",
        "    properties = set()\n",
        "    for metric in metrics:\n",
        "        for property in metric:\n",
        "            properties.add(property)\n",
        "    grouped_metrics = {}\n",
        "    for property in properties:\n",
        "        grouped_metrics[property] = [metric for metric in metrics if property in metric]\n",
        "    return grouped_metrics\n",
        "def agrupar_propiedades(lista):\n",
        "    resultado = {}\n",
        "    for diccionario in lista:\n",
        "        for propiedad, valor in diccionario.items():\n",
        "            # Reemplazar espacios y caracteres especiales en la propiedad con guiones bajos\n",
        "            propiedad = propiedad.replace(' ', '_').replace('-', '_')\n",
        "            if propiedad not in resultado:\n",
        "                resultado[propiedad] = []\n",
        "            resultado[propiedad].append(valor)\n",
        "    return resultado\n",
        "\n",
        "def _getvalores(data,key):{\n",
        "  [metric[key] for metric in data if key in data]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def normalizar_propiedades(lista):\n",
        "    for diccionario in lista:\n",
        "        for propiedad in list(diccionario.keys()):\n",
        "            propiedad_normalizada = propiedad.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\".\", \"_\").replace(\":\", \"_\").replace(\"/\", \"_\")\n",
        "            if propiedad != propiedad_normalizada:\n",
        "                diccionario[propiedad_normalizada] = diccionario.pop(propiedad)\n",
        "    return lista\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BznIdYZ1stqI"
      },
      "outputs": [],
      "source": [
        "def generarGrafico(metrics,numero=2):\n",
        "    metricas2 = agrupar_propiedades(metrics)\n",
        "    fecha_hora = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    # Configurar el gráfico\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.title('Métricas de entrenamiento por época')\n",
        "    plt.xlabel('Época')\n",
        "    plt.ylabel('Valor de la métrica')\n",
        "    plt.ylim(0, 1.5)\n",
        "\n",
        "    # Graficar cada métrica con longitud distinta a 7\n",
        "    for name, valores in metricas2.items():\n",
        "        if len(valores) == numero:  # Verificar si la longitud es igual a 7\n",
        "            plt.plot(range(len(valores)), valores, label=name,marker='o')\n",
        "\n",
        "    # Agregar leyenda y mostrar gráfico\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Establecer valores y etiquetas en el eje y con todos los decimales\n",
        "    plt.yticks([i / 10 for i in range(15)])\n",
        "\n",
        "    # Agregar fecha y hora al pie de la gráfica\n",
        "    plt.figtext(0.99, 0.01, fecha_hora, ha='right', va='bottom')\n",
        "    ruta =GenerarDirectorio('Graficos')\n",
        "       # Ajustar el tamaño de la gráfica dentro de la ventana\n",
        "     # Guardar el gráfico en la ubicación especificada con mayor resolución\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(os.path.join(ruta, f'{date_string}_grafico.png'), dpi=1800,bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ893HRNrd16"
      },
      "outputs": [],
      "source": [
        "def GenerarMatrizConfuncion(matriz_confusion):\n",
        "    # Configurar el gráfico\n",
        "    plt.imshow(matriz_confusion, cmap='Blues', interpolation='nearest')\n",
        "    plt.title('Matriz de Confusión')\n",
        "    plt.colorbar()\n",
        "\n",
        "    # Etiquetas de los ejes x e y\n",
        "    tick_marks = np.arange(len(matriz_confusion))\n",
        "    plt.xticks(tick_marks, ['Negativo', 'Positivo'])\n",
        "    plt.yticks(tick_marks, ['Negativo', 'Positivo'])\n",
        "\n",
        "    # Mostrar los valores de la matriz de confusión en cada celda\n",
        "    thresh = matriz_confusion.max() / 2.\n",
        "    for i, j in np.ndindex(matriz_confusion.shape):\n",
        "        plt.text(j, i, format(matriz_confusion[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if matriz_confusion[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.figtext(0.99, 0.01, date_string, ha='right', va='bottom')\n",
        "    ruta =GenerarDirectorio('Graficos')\n",
        "    # Ajustar los márgenes del gráfico\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(os.path.join(ruta, f'{date_string}_matrizConfusion.png'), dpi=1800,bbox_inches='tight')\n",
        "    # Mostrar el gráfico\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pia9vcZtsy_X"
      },
      "outputs": [],
      "source": [
        "metrics=trainer.state.log_history\n",
        "metrics=normalizar_propiedades(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5D6t9pJs1R7"
      },
      "outputs": [],
      "source": [
        "generarGrafico(metrics,args.num_train_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNSvpPJzodIQ"
      },
      "outputs": [],
      "source": [
        "direccion=GenerarDirectorio('best_model')\n",
        "rutamodel=os.path.join(direccion,'best_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqDrwG_to88s"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model, rutamodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izjkwOrZo_i0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "modelo_cargado = torch.load(rutamodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOsDJ03-pFCA"
      },
      "outputs": [],
      "source": [
        "modelo_cargado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvtjVqyj8GRM"
      },
      "outputs": [],
      "source": [
        "train_prueba=train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhiLghAigvZy"
      },
      "outputs": [],
      "source": [
        "train_input_ids = [train_prueba[i]['input_ids'] for i in range(len(train_prueba))]\n",
        "train_attention_mask = [train_prueba[i]['attention_mask'] for i in range(len(train_prueba))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBBg8OYEpmh3"
      },
      "outputs": [],
      "source": [
        "train_input_ids_tensor = torch.stack(train_input_ids)  # Convertir la lista en un tensor\n",
        "train_attention_mask_tensor = torch.stack(train_attention_mask)  # Convertir la lista en un tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3wxhTWlg1Gj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Realizar las predicciones con el modelo cargado\n",
        "predicciones = modelo_cargado.predict(train_input_ids_tensor, train_attention_mask_tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q1AZ4bpg3Kh"
      },
      "outputs": [],
      "source": [
        "predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSeyAQEy-MhV"
      },
      "outputs": [],
      "source": [
        "prediciones = trainer.predict(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndFa6SdcqXDL"
      },
      "outputs": [],
      "source": [
        "prediciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84sP7OWarIkg"
      },
      "outputs": [],
      "source": [
        "predicciones=prediciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3nq9eE-rLKW"
      },
      "outputs": [],
      "source": [
        "reponsestrue= predicciones.predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GZpQr9DrPgE"
      },
      "outputs": [],
      "source": [
        "reponsestrue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBmrXefHrSP0"
      },
      "outputs": [],
      "source": [
        "preds = np.argmax(reponsestrue,axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFKlyz7HrUwL"
      },
      "outputs": [],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-1maKPcrWQ9"
      },
      "outputs": [],
      "source": [
        "labels_idsbin= torch.from_numpy(predicciones.label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L03gA67GrX_D"
      },
      "outputs": [],
      "source": [
        "labels_idsbin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkbZNYkKrbJr"
      },
      "outputs": [],
      "source": [
        "bin_labels = torch.argmax(labels_idsbin, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xxRKuaDsvR9"
      },
      "outputs": [],
      "source": [
        "bin_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn_ZX7w0rpnv"
      },
      "outputs": [],
      "source": [
        "matriz_confusion = confusion_matrix(bin_labels, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9sj96KDsllz"
      },
      "outputs": [],
      "source": [
        "matriz_confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7IegR06rtre"
      },
      "outputs": [],
      "source": [
        "GenerarMatrizConfuncion(matriz_confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggb4FLiLp9g9"
      },
      "outputs": [],
      "source": [
        "evaluacion = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TakZXhPYqCQ2"
      },
      "outputs": [],
      "source": [
        "evaluacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPvXDcye-MhW"
      },
      "outputs": [],
      "source": [
        "print (prediciones.predictions.shape, prediciones.label_ids.shape)\n",
        "print (prediciones.predictions, prediciones.label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAVzwQMiFTKr"
      },
      "outputs": [],
      "source": [
        "evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZn16iIGxmK_"
      },
      "outputs": [],
      "source": [
        "evaluacio=model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdXqo5NEYs8W"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
